import av
import streamlit as st
import time
from PIL import Image
from streamlit_webrtc import WebRtcMode, VideoProcessorBase, webrtc_streamer

from services.deepface_service import analyze_emotion
from services.gemini_service import (
    get_gemini_api_key,
    init_gemini,
    create_emotion_intro,
)
from services.emotion_agent_service import (
    generate_advice_with_memory_from_result,
)

from services.tts_service import text_to_speech_file, estimate_speech_duration, cleanup_audio_file


# ===========================
# Phase labels (0..5) - TI·∫æNG VI·ªÜT
# ===========================
PHASE_LABELS = {
    0: "·∫§n t∆∞·ª£ng ban ƒë·∫ßu khi kh√°ch v·ª´a b∆∞·ªõc v√†o nh√† h√†ng",
    1: "ƒê√°nh gi√° th√°i ƒë·ªô v√† c√°ch ph·ª•c v·ª• c·ªßa nh√¢n vi√™n b·ªìi b√†n",
    2: "ƒê√°nh gi√° tr√¨nh b√†y m√≥n ƒÉn khi ƒë∆∞·ª£c mang ra",
    3: "ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng m√≥n ƒÉn khi kh√°ch ƒëang ƒÉn",
    4: "Kh√°ch tr√≤ chuy·ªán ‚Äì ch·ªâ quan s√°t, kh√¥ng suy di·ªÖn th√†nh ƒë√°nh gi√° d·ªãch v·ª•",
    5: "Tr·∫°ng th√°i b√¨nh th∆∞·ªùng (sau c√°c phase ƒë·∫∑c bi·ªát / kh√¥ng v√†o phase)"
}


class EmotionVideoProcessor(VideoProcessorBase):
    """
    Video processor d√πng cho streamlit-webrtc.
    Ch·ªâ gi·ªØ frame m·ªõi nh·∫•t t·ª´ camera, ƒë·ªÉ thread ch√≠nh quy·∫øt ƒë·ªãnh khi n√†o ch·ª•p.
    """

    def __init__(self):
        # Frame BGR m·ªõi nh·∫•t t·ª´ camera
        self.last_frame_bgr = None
        # ·∫¢nh ƒë√£ ƒë∆∞·ª£c "ch·ª•p" (PIL Image) gi·ªëng nh∆∞ Take photo
        self.captured_image = None
        # K·∫øt qu·∫£ ph√¢n t√≠ch c·∫£m x√∫c g·∫ßn nh·∫•t
        self.last_result = None

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        # L∆∞u frame m·ªõi nh·∫•t, kh√¥ng ph√¢n t√≠ch t·∫°i ƒë√¢y
        img_bgr = frame.to_ndarray(format="bgr24")
        self.last_frame_bgr = img_bgr
        return frame


def render_camera_auto(interval_seconds: int = 15):
    """
    Giao di·ªán v√† logic cho ch·∫ø ƒë·ªô Camera auto.
    Sequential flow: Detect emotion ‚Üí Call Gemini ‚Üí Show response ‚Üí Detect ti·∫øp
    """

    st.subheader("ü§ñ Tr·ª£ l√Ω c·∫£m x√∫c AI - Ch·∫ø ƒë·ªô t·ª± ƒë·ªông (6 phase)")
    st.write(
        "**Quy tr√¨nh:** Detect c·∫£m x√∫c ‚Üí AI ph√¢n t√≠ch ‚Üí Detect ti·∫øp\n\n"
        "Khi b·∫≠t 'T·ª± ƒë·ªông detect', 6 l·∫ßn detect ƒë·∫ßu s·∫Ω t∆∞∆°ng ·ª©ng c√°c phase 0..5 (xem nh√£n). "
        "Sau khi ho√†n t·∫•t 6 phase, h·ªá th·ªëng s·∫Ω chuy·ªÉn v·ªÅ tr·∫°ng th√°i b√¨nh th∆∞·ªùng (phase 5)."
    )

    # -------------------------
    # session_state defaults
    # -------------------------
    if "previous_emotion" not in st.session_state:
        st.session_state.previous_emotion = None
    if "is_gemini_processing" not in st.session_state:
        st.session_state.is_gemini_processing = False
    if "last_gemini_suggestion" not in st.session_state:
        st.session_state.last_gemini_suggestion = None
    if "last_detection_time" not in st.session_state:
        st.session_state.last_detection_time = 0
    if "waiting_for_ai" not in st.session_state:
        st.session_state.waiting_for_ai = False
    if "is_playing_audio" not in st.session_state:
        st.session_state.is_playing_audio = False
    if "current_audio_file" not in st.session_state:
        st.session_state.current_audio_file = None

    # detect_count: s·ªë l·∫ßn special-phase ƒë√£ ch·∫°y (0..6). Khi <6 v√† auto_mode th√¨ s·∫Ω l·∫•y phase = detect_count (0..5)
    if "detect_count" not in st.session_state:
        st.session_state.detect_count = 0

    # l∆∞u phase active g·∫ßn nh·∫•t (0..5). M·∫∑c ƒë·ªãnh l√† 5 (b√¨nh th∆∞·ªùng)
    if "current_phase" not in st.session_state:
        st.session_state.current_phase = 5

    # force_detect flag
    if "force_detect" not in st.session_state:
        st.session_state.force_detect = False

    # Control buttons
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("üîÑ Reset v√† b·∫Øt ƒë·∫ßu l·∫°i"):
            st.session_state.previous_emotion = None
            st.session_state.last_gemini_suggestion = None
            st.session_state.waiting_for_ai = False
            st.session_state.is_gemini_processing = False
            st.session_state.last_detection_time = 0
            st.session_state.force_detect = True
            st.session_state.detect_count = 0
            st.session_state.current_phase = 5
            st.success("‚úÖ ƒê√£ reset! S·∫µn s√†ng detect c·∫£m x√∫c m·ªõi.")
            st.rerun()  # <--- ƒê√É S·ª¨A

    with col2:
        if st.button("‚ñ∂Ô∏è Detect c·∫£m x√∫c ngay"):
            st.session_state.waiting_for_ai = False
            st.session_state.last_detection_time = 0
            st.session_state.force_detect = True
            st.rerun()  # <--- ƒê√É S·ª¨A

    with col3:
        auto_mode = st.checkbox("üîÑ T·ª± ƒë·ªông detect", value=False, key="auto_detect_mode")

    # TTS settings
    tts_enabled = st.checkbox("üîä B·∫≠t ƒë·ªçc text-to-speech", value=True, key="tts_enabled")

    # -------------------------
    # webrtc streamer
    # -------------------------
    webrtc_ctx = webrtc_streamer(
        key=f"emotion-auto-{interval_seconds}",
        mode=WebRtcMode.SENDRECV,
        media_stream_constraints={"video": True, "audio": False},
        video_processor_factory=EmotionVideoProcessor,
    )

    result_placeholder = st.empty()
    chart_placeholder = st.empty()
    suggestion_placeholder = st.empty()
    status_placeholder = st.empty()
    audio_placeholder = st.empty()

    # -------------------------
    # n·∫øu webrtc s·∫µn s√†ng
    # -------------------------
    if webrtc_ctx.video_processor is not None:
        processor = webrtc_ctx.video_processor

        # n·∫øu h·ªá th·ªëng ƒëang ch·ªù k·∫øt qu·∫£ Gemini, hi·ªÉn th·ªã tr·∫°ng th√°i v√† k·∫øt qu·∫£ c≈©
        if st.session_state.is_gemini_processing or st.session_state.waiting_for_ai:
            status_placeholder.info("‚è≥ **ƒêang ch·ªù AI tr·∫£ l·ªùi...** Vui l√≤ng ƒë·ª£i.")
            if processor.last_result:
                result = processor.last_result
                dominant_emotion = result.get("dominant_emotion")
                emotions = result.get("emotion", {})
                result_placeholder.success(f"**C·∫£m x√∫c ch√≠nh**: {dominant_emotion}")
                if emotions:
                    chart_placeholder.subheader("Chi ti·∫øt c√°c c·∫£m x√∫c")
                    chart_placeholder.bar_chart(emotions)
            if st.session_state.last_gemini_suggestion:
                suggestion_placeholder.markdown(
                    f"### üí¨ G·ª£i √Ω t·ª´ tr·ª£ l√Ω nh√† h√†ng\n\n{st.session_state.last_gemini_suggestion}"
                )
            # kh√¥ng ƒëi ti·∫øp khi ch·ªù AI
            return

        # Ki·ªÉm tra c√≥ n√™n detect kh√¥ng (auto mode ho·∫∑c force detect ho·∫∑c qu√° th·ªùi gian)
        should_detect = (
            st.session_state.force_detect
            or auto_mode
            or st.session_state.last_detection_time == 0
            or (time.time() - st.session_state.last_detection_time) > interval_seconds
        )

        # Reset force_detect flag n·∫øu ƒë√£ d√πng
        if st.session_state.force_detect:
            st.session_state.force_detect = False

        # N·∫øu c√≥ frame v√† c·∫ßn detect
        if should_detect and processor.last_frame_bgr is not None:
            try:
                frame_rgb = processor.last_frame_bgr[:, :, ::-1]  # BGR -> RGB
                image = Image.fromarray(frame_rgb)
                processor.captured_image = image

                # Ph√¢n t√≠ch c·∫£m x√∫c (DeepFace)
                with st.spinner("üîç ƒêang ph√¢n t√≠ch c·∫£m x√∫c..."):
                    result = analyze_emotion(image)
                processor.last_result = result
                st.session_state.last_detection_time = time.time()

            except Exception as e:
                # Kh√¥ng ƒë·ªÉ exception l√†m crash app
                st.warning(f"L·ªói khi detect c·∫£m x√∫c: {e}")
                # hi·ªÉn th·ªã l·ªói trong status, nh∆∞ng ti·∫øp t·ª•c (kh√¥ng reset state)
                status_placeholder.error(f"L·ªói detect: {e}")
                return

        # Hi·ªÉn th·ªã ·∫£nh ƒë√£ capture
        if processor.captured_image is not None:
            st.image(
                processor.captured_image,
                caption="·∫¢nh ƒë√£ capture",
                width='stretch',
            )

        # N·∫øu c√≥ k·∫øt qu·∫£ ph√¢n t√≠ch th√¨ x·ª≠ l√Ω
        result = processor.last_result
        if not result:
            # ch∆∞a c√≥ k·∫øt qu·∫£
            if processor.last_frame_bgr is None:
                result_placeholder.info(
                    "üì∑ **ƒêang ch·ªù camera...** H√£y ƒë·∫£m b·∫£o camera ƒë√£ ƒë∆∞·ª£c b·∫≠t v√† cho ph√©p truy c·∫≠p."
                )
            else:
                result_placeholder.info("üí° Nh·∫•n 'Detect c·∫£m x√∫c ngay' ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")
            return

        # --- l·∫•y k·∫øt qu·∫£ c·∫£m x√∫c ---
        dominant_emotion = result.get("dominant_emotion")
        emotions = result.get("emotion", {})

        result_placeholder.success(f"**C·∫£m x√∫c ch√≠nh**: {dominant_emotion}")
        if emotions:
            chart_placeholder.subheader("Chi ti·∫øt c√°c c·∫£m x√∫c")
            chart_placeholder.bar_chart(emotions)

        # -------------------------
        # X√ÅC ƒê·ªäNH PHASE
        # Logic:
        # - N·∫øu auto_mode is True v√† detect_count < 6: phase = detect_count (0..5), sau khi x·ª≠ l√Ω th√†nh c√¥ng tƒÉng detect_count
        # - N·∫øu auto_mode False: gi·ªØ current_phase (do user ch·ªçn ho·∫∑c default)
        # - Khi detect_count >=6 => current_phase = 5 (b√¨nh th∆∞·ªùng)
        # -------------------------
        if auto_mode:
            if st.session_state.detect_count < 6:
                phase = st.session_state.detect_count  # 0..5
            else:
                phase = 5
        else:
            # manual mode -> s·ª≠ d·ª•ng current_phase (m·∫∑c ƒë·ªãnh 5)
            phase = st.session_state.current_phase if isinstance(st.session_state.current_phase, int) else 5

        # Hi·ªÉn th·ªã nh√£n phase hi·ªán t·∫°i
        phase_label = PHASE_LABELS.get(phase, "Tr·∫°ng th√°i kh√¥ng x√°c ƒë·ªãnh")
        status_placeholder.info(f"üîé Phase {phase}: {phase_label}")

        # -------------------------
        # G·ªåI GEMINI (ho·∫∑c agent) CH·ªà KHI:
        # - model key c√≥ s·∫µn
        # - v√† (c·∫£m x√∫c thay ƒë·ªïi so v·ªõi previous_emotion) OR (l·∫ßn ƒë·∫ßu cho phase n√†y)
        # -------------------------
        api_key = get_gemini_api_key()
        if not api_key:
            suggestion_placeholder.warning(
                "‚ö†Ô∏è **Ch∆∞a t√¨m th·∫•y Gemini API key!**\n\n"
                "Vui l√≤ng: t·∫°o file `.env` v·ªõi GEMINI_API_KEY=your_key_here ho·∫∑c nh·∫≠p ·ªü sidebar."
            )
            return

        # Kh·ªüi t·∫°o model 1 l·∫ßn / session
        if "gemini_model" not in st.session_state:
            try:
                with st.spinner("ƒêang kh·ªüi t·∫°o Gemini model..."):
                    model, model_info = init_gemini(api_key)
                if model is None:
                    suggestion_placeholder.error(f"‚ùå L·ªói kh·ªüi t·∫°o Gemini: {model_info}")
                    return
                st.session_state.gemini_model = model
                st.session_state.gemini_model_name = model_info
            except Exception as e:
                suggestion_placeholder.error(f"‚ùå L·ªói khi kh·ªüi t·∫°o Gemini: {e}")
                return

        model = st.session_state.get("gemini_model")

        # Quy·∫øt ƒë·ªãnh c√≥ g·ªçi AI hay kh√¥ng
        previous_emotion = st.session_state.previous_emotion
        # track first call per phase to allow AI even n·∫øu emotion kh√¥ng ƒë·ªïi
        if "phase_called" not in st.session_state:
            st.session_state.phase_called = set()

        need_call_ai = False
        # N·∫øu c·∫£m x√∫c thay ƒë·ªïi so v·ªõi tr∆∞·ªõc ƒë√≥ -> g·ªçi
        if previous_emotion is None or previous_emotion != dominant_emotion:
            need_call_ai = True
        # Ho·∫∑c l·∫ßn ƒë·∫ßu cho phase n√†y (ch∆∞a g·ªçi AI cho phase)
        if phase not in st.session_state.phase_called:
            need_call_ai = True

        if need_call_ai:
            # set flags
            st.session_state.is_gemini_processing = True
            st.session_state.waiting_for_ai = True

            with st.spinner(f"ü§î AI tr·ª£ l√Ω nh√† h√†ng ƒëang ph√¢n t√≠ch c·∫£m x√∫c '{dominant_emotion}' (phase {phase})..."):
                try:
                    suggestion_text = generate_advice_with_memory_from_result(
                        model=model,
                        dominant_emotion=dominant_emotion,
                        emotions=emotions,
                        phase=phase,
                        user_id="default_user",
                    )
                except Exception as e:
                    suggestion_text = f"‚ö†Ô∏è L·ªói khi g·ªçi Gemini: {e}"
                # ƒë·∫£m b·∫£o kh√¥ng n√©m exception ra ngo√†i

            # clear flags
            st.session_state.is_gemini_processing = False
            st.session_state.waiting_for_ai = False

            # l∆∞u k·∫øt qu·∫£
            st.session_state.previous_emotion = dominant_emotion
            st.session_state.last_gemini_suggestion = suggestion_text
            st.session_state.phase_called.add(phase)
            st.session_state.current_phase = phase

            # hi·ªÉn th·ªã
            if suggestion_text and suggestion_text.strip():
                if suggestion_text.startswith("‚ö†Ô∏è"):
                    suggestion_placeholder.warning(suggestion_text)
                    status_placeholder.warning("‚ö†Ô∏è C√≥ l·ªói x·∫£y ra khi g·ªçi AI")
                    # V·∫´n tƒÉng detect_count k·ªÉ c·∫£ khi AI l·ªói
                    if auto_mode and phase < 5 and st.session_state.detect_count == phase:
                        st.session_state.detect_count += 1
                        st.session_state.last_detection_time = 0
                        st.rerun()  # <--- ƒê√É S·ª¨A
                else:
                    suggestion_placeholder.markdown(
                        f"### üí¨ G·ª£i √Ω t·ª´ tr·ª£ l√Ω nh√† h√†ng (Phase {phase})\n\n{suggestion_text}"
                    )

                    # TTS (t√πy ch·ªçn)
                    if tts_enabled:
                        try:
                            st.session_state.is_playing_audio = True

                            emotion_intro = create_emotion_intro(dominant_emotion)
                            full_text_to_speak = f"{emotion_intro} {suggestion_text}"

                            audio_file = text_to_speech_file(full_text_to_speak, lang="vi", slow=False)
                            if audio_file:
                                st.session_state.current_audio_file = audio_file
                                audio_placeholder.audio(audio_file, format="audio/mp3", autoplay=True)

                                # estimate duration (fallback 2s n·∫øu l·ªói)
                                try:
                                    estimated_duration = estimate_speech_duration(full_text_to_speak)
                                    time_to_wait = max(1.0, float(estimated_duration) + 0.5)
                                except Exception:
                                    time_to_wait = 2.0

                                status_placeholder.info(f"üîä ƒêang ph√°t audio... (∆∞·ªõc t√≠nh ~{int(time_to_wait)}s)")

                                # ƒë·ª£i m·ªôt ch√∫t cho audio play (kh√¥ng kh·ªëi qu√° l√¢u)
                                time.sleep(time_to_wait)

                                # cleanup
                                cleanup_audio_file(audio_file)
                                st.session_state.is_playing_audio = False
                                st.session_state.current_audio_file = None

                                status_placeholder.success("‚úÖ ƒê√£ ƒë·ªçc xong! S·∫µn s√†ng detect ti·∫øp theo.")
                                
                                # TƒÉng detect_count ƒë·ªÉ chuy·ªÉn sang phase ti·∫øp theo
                                if auto_mode and phase < 5 and st.session_state.detect_count == phase:
                                    st.session_state.detect_count += 1
                                    st.session_state.last_detection_time = 0
                                    st.rerun()  # <--- ƒê√É S·ª¨A

                            else:
                                st.session_state.is_playing_audio = False
                                status_placeholder.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o audio. Ti·∫øp t·ª•c detect...")
                        except Exception as e:
                            # Kh√¥ng ƒë·ªÉ l·ªói TTS l√†m crash
                            st.warning(f"L·ªói TTS: {e}")
                            st.session_state.is_playing_audio = False
                    else:
                        status_placeholder.success("‚úÖ AI ƒë√£ tr·∫£ l·ªùi xong! S·∫µn s√†ng detect ti·∫øp theo.")
                        
                        # TƒÉng detect_count ƒë·ªÉ chuy·ªÉn sang phase ti·∫øp theo
                        if auto_mode and phase < 5 and st.session_state.detect_count == phase:
                            st.session_state.detect_count += 1
                            st.session_state.last_detection_time = 0
                            st.rerun()  # <--- ƒê√É S·ª¨A
            else:
                suggestion_placeholder.error("‚ùå Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi t·ª´ AI.")
        else:
            # kh√¥ng c·∫ßn g·ªçi AI, hi·ªÉn th·ªã suggestion c≈© (n·∫øu c√≥)
            if st.session_state.last_gemini_suggestion:
                suggestion_placeholder.markdown(
                    f"### üí¨ G·ª£i √Ω t·ª´ tr·ª£ l√Ω nh√† h√†ng (c≈©)\n\n{st.session_state.last_gemini_suggestion}"
                )
            status_placeholder.info("‚ÑπÔ∏è C·∫£m x√∫c kh√¥ng thay ƒë·ªïi v√† phase ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω tr∆∞·ªõc ƒë√≥. Ti·∫øp t·ª•c detect...")

        # N·∫øu auto_mode b·∫≠t nh∆∞ng ƒë√£ ho√†n t·∫•t 6 phase, ƒë·∫∑t current_phase = 5 (b√¨nh th∆∞·ªùng)
        if auto_mode and st.session_state.detect_count >= 6:
            st.session_state.current_phase = 5